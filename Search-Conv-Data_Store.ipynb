{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a331300-5ff3-4219-83c0-ce11703cc9e1",
   "metadata": {},
   "source": [
    "# How To Create a Vertex Search AI Data Store with JSON Using Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34429b82-078c-4107-827d-8aaed4ab1121",
   "metadata": {},
   "source": [
    "This notebook outlines how to create a structured data store in Vertex Search and Conversationl AI. In this example we will generate a JSON data set from items in an image using Gemini-Pro-Vision and then use that data to create the Vertex Search AI data store. After creating the data store, we will perform a query and optionally pass the query and the results to Gemini-Pro to produce the final answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ed54ec-9f36-40af-8d2e-c6fd32a76222",
   "metadata": {},
   "source": [
    "## Prepare the python development environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906ce888-8c52-476b-96d0-7f65cb259f8d",
   "metadata": {},
   "source": [
    "First, let's identify any project specific variables to customize this notebook to your GCP environment. Change YOUR_PROJECT_ID with your own GCP project ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205088b5-6d5b-46dd-9d77-a8352eac630b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'rkiles-demo-host-vpc'\n",
    "REGION = 'us-central1'\n",
    "LOCATION = 'global'\n",
    "#DSNAME = \"json-test-datastore\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e7d4bb-dd35-4477-b94a-8666cf0f9695",
   "metadata": {},
   "source": [
    "Next, let's specify the name of the image file you want to inspect, such as \"OJ.png\" or \"shoe.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba226a4-d673-4778-8cbd-c32dc88b1389",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_filename = 'stuff_on_a_shelf.jpg'\n",
    "#image_filename = 'OJ.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe92738a-045b-48a4-ab0e-1d98fad2089a",
   "metadata": {},
   "source": [
    "Install any needed python modules from our requirements.txt file. Most Vertex Workbench environments include all the packages we'll be using, but if you are using an external Jupyter Notebook or require any additional packages for your own needs, you can simply add them to the included requirements.txt file an run the folloiwng commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69175b8-63c4-4b5a-837d-055743c0b8d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444b2ce7-0277-4ada-9648-34c67774bfd2",
   "metadata": {},
   "source": [
    "Now we will import all required modules. For our purpose, we will be utilizing the following:\n",
    "\n",
    "- vertexai - Provides authentication access to the Google API's, such as imagegeneration:predict\n",
    "- vertexai.preview.generative_models - Interact with new multimodal models\n",
    "- base64 - Imagen API requests return generated or edited images as base64-encoded strings. This module will help us decode this data to an image file\n",
    "- json - Python module used to interact with JSON data. Imagen returns results in json format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e15897-0cb0-4173-9b91-17270a10b989",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.preview.generative_models import GenerativeModel, Part\n",
    "#from vertexai.generative_models import GenerativeModel, Part\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import aiplatform_v1beta1 as vertex_ai\n",
    "\n",
    "from typing import List\n",
    "from google.api_core.client_options import ClientOptions\n",
    "\n",
    "from google.cloud import discoveryengine_v1beta as discoveryengine\n",
    "\n",
    "import base64\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2b2668-962a-42da-b92b-4932f224bb0d",
   "metadata": {},
   "source": [
    "## Instantiate Vertex AI ojbect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc262a0-fad5-4f15-aee3-cf9ce36a78b0",
   "metadata": {},
   "source": [
    "To use Gemini Vision Pro on Vertex AI you must provide a text description of what you want to inspect, generate or edit. These descriptions are called prompts, and these prompts are the primary way you communicate with Generative AI. Here, we are specifiying what we want the model to identify using a prompt. Play around with this content and see what kind of details you can extract from an image. More information can be found here https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c42ad98-e2f9-4c04-a1eb-8f42d2bb1b5e",
   "metadata": {},
   "source": [
    "In this example, we will ask Gemini to inspect a picture of an orange juice carton and provide it's results in a json format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c9ba6f-3c32-4e94-b9ed-779d24db6dac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vqa_prompt = 'Briefly describe each product you see in this picture and provide your response in JSON format. Include the brand, description, size, price, item number, bay and location. If you can not determine the size, mark it as NA. Do not include the json prefix in your response.'\n",
    "#vqa_prompt = 'Briefly describe each product you see in this picture and provide your response in JSON format. Include the brand, description and size. If you can not determine the size, mark it as NA'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b40b114-aae7-4cfb-9c20-34bc6773c178",
   "metadata": {},
   "source": [
    "Next we define a function to build the request to be sent to the multimodal model. This will create a base64 encoded string of a local image and uses the from_data function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b9d834-c641-4ff3-bd90-8b1ad90c5722",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(image_filename, \"rb\") as f:\n",
    "    encoded_base_image = base64.b64encode(f.read())\n",
    "B64_BASE_IMAGE = encoded_base_image.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a94e84e-8fd3-418a-9b54-71c43fd34e01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_text(project_id: str, location: str, b64_image: str, prompt: str) -> str:\n",
    "    # Initialize Vertex AI\n",
    "    vertexai.init(project=project_id, location=location)\n",
    "    # Load the model\n",
    "    multimodal_model = GenerativeModel(\"gemini-pro-vision\")\n",
    "    # Query the model\n",
    "    response = multimodal_model.generate_content(\n",
    "        [\n",
    "            # Add an example image\n",
    "            Part.from_data(\n",
    "                data=base64.b64decode(b64_image), mime_type=\"image/png\"\n",
    "            ),\n",
    "            #\"what is shown in this image?\",\n",
    "            vqa_prompt,\n",
    "        ]\n",
    "    )\n",
    "    #print(response)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3fb974-e836-40c5-81e3-c83f63bc84e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Send the request and display the response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93462b3-7ee7-4f6f-a141-0d54ce304669",
   "metadata": {
    "tags": []
   },
   "source": [
    "Call the above generate_text fuction and display the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32a6c60-9040-4f58-9d25-383e25b86360",
   "metadata": {},
   "outputs": [],
   "source": [
    "#qa_response = json.loads(generate_text(PROJECT_ID, LOCATION, B64_BASE_IMAGE, vqa_prompt))\n",
    "qa_response = generate_text(PROJECT_ID, REGION, B64_BASE_IMAGE, vqa_prompt)\n",
    "print(qa_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff660fc-81fb-45b5-9132-8b3e4b002e25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3dd5b22d-1b4b-4a4e-845f-7a236ba18f43",
   "metadata": {},
   "source": [
    "Define a function to create a new VAIS Data Store "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c62234-0156-4014-8398-2ee6e5937624",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample_create_data_store(project_id, location, display_name):\n",
    "    # Create a client\n",
    "    client = discoveryengine.DataStoreServiceClient()\n",
    "\n",
    "    # Initialize request argument(s)\n",
    "    data_store = discoveryengine.DataStore()\n",
    "    data_store.display_name = display_name\n",
    "    data_store.industry_vertical = 'GENERIC'\n",
    "\n",
    "    request = discoveryengine.CreateDataStoreRequest(\n",
    "        #parent=f\"projects/{project_id}/locations/{location}\",\n",
    "        parent=f\"projects/{project_id}/locations/{location}/collections/default_collection\",\n",
    "        data_store=data_store,\n",
    "        data_store_id = display_name\n",
    "    )\n",
    "\n",
    "    # Make the request\n",
    "    operation = client.create_data_store(request=request)\n",
    "\n",
    "    print(\"Waiting for operation to complete...\")\n",
    "\n",
    "    response = operation.result()\n",
    "\n",
    "    # Handle the response\n",
    "    print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cb2935-32c1-407c-88d6-c90323029c82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create_and_upload_datastore(PROJECT_ID, LOCATION, DSNAME, qa_response, qa_schema)\n",
    "sample_create_data_store(PROJECT_ID, LOCATION, DSNAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694cdc15-69b6-4e93-b88d-7adf2e70c838",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d62da5c4-5028-4f39-9c1d-d20e4d01c008",
   "metadata": {},
   "source": [
    "Define a function to create a new document in the Data Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376719c1-a6c8-4031-a195-6c4bcc8c5238",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample_create_document(project_id, location, datastore_name, document_id, json_string):\n",
    "    # Create a client\n",
    "    client = discoveryengine.DocumentServiceClient()\n",
    "\n",
    "    # Initialize request argument(s)\n",
    "    request = discoveryengine.CreateDocumentRequest(\n",
    "        parent=f\"projects/{project_id}/locations/{location}/collections/default_collection/dataStores/{datastore_name}/branches/0\",\n",
    "        document = discoveryengine.Document(struct_data=json_string),\n",
    "        document_id=document_id,\n",
    "    )\n",
    "\n",
    "    # Make the request\n",
    "    response = client.create_document(request=request)\n",
    "\n",
    "    # Handle the response\n",
    "    print(response)\n",
    "\n",
    "# [END discoveryengine_v1_generated_DocumentService_CreateDocument_sync]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85e3713-869a-450e-8552-2280d9a137b1",
   "metadata": {},
   "source": [
    "Create a new document in the data store for each identified item from the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0923188a-527d-4bd1-8842-cc225f364352",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qa_json = json.loads(qa_response)\n",
    "\n",
    "recordnum = 0\n",
    "\n",
    "for brand in qa_json['products']:\n",
    "    sample_create_document(PROJECT_ID, LOCATION, DSNAME, 'record'+str(recordnum), brand)\n",
    "    recordnum = recordnum + 1\n",
    "    #print(brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca37a01-1891-49cc-b4f1-642db32de2cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66eaa5fe-b079-44d1-b83d-982a56f49962",
   "metadata": {},
   "source": [
    "Define a function to search the data store based on the information from the user prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861a18b6-9083-49fa-8f0a-1caf0b293809",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def search_sample(project_id, location, engine_id, search_query) -> List[discoveryengine.SearchResponse]:\n",
    "\n",
    "    client_options = (\n",
    "        ClientOptions(api_endpoint=f\"{location}-discoveryengine.googleapis.com\")\n",
    "        if location != \"global\"\n",
    "        else None\n",
    "    )\n",
    "    \n",
    "    # Create a client\n",
    "    client = discoveryengine.SearchServiceClient(client_options=client_options)\n",
    "    \n",
    "    # The full resource name of the search app serving config\n",
    "    serving_config = f\"projects/{project_id}/locations/{location}/collections/default_collection/engines/{engine_id}/servingConfigs/default_config\"\n",
    "    \n",
    "    \n",
    "    content_search_spec = discoveryengine.SearchRequest.ContentSearchSpec(\n",
    "        # For information about snippets, refer to:\n",
    "        # https://cloud.google.com/generative-ai-app-builder/docs/snippets\n",
    "        snippet_spec=discoveryengine.SearchRequest.ContentSearchSpec.SnippetSpec(\n",
    "            return_snippet=True\n",
    "            ),\n",
    "        # For information about search summaries, refer to:\n",
    "        # https://cloud.google.com/generative-ai-app-builder/docs/get-search-summaries\n",
    "        summary_spec=discoveryengine.SearchRequest.ContentSearchSpec.SummarySpec(\n",
    "            summary_result_count=5,\n",
    "            include_citations=True,\n",
    "            ignore_adversarial_query=True,\n",
    "            ignore_non_summary_seeking_query=True,\n",
    "            model_prompt_spec=discoveryengine.SearchRequest.ContentSearchSpec.SummarySpec.ModelPromptSpec(\n",
    "                preamble=\"\"\n",
    "            ),\n",
    "            model_spec=discoveryengine.SearchRequest.ContentSearchSpec.SummarySpec.ModelSpec(\n",
    "                version=\"gemini-1.0-pro-001/answer_gen/v1\",\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "    request = discoveryengine.SearchRequest(\n",
    "        serving_config=serving_config,\n",
    "        query=search_query,\n",
    "        #page_size=1,\n",
    "        content_search_spec=content_search_spec,\n",
    "        query_expansion_spec=discoveryengine.SearchRequest.QueryExpansionSpec(\n",
    "            condition=discoveryengine.SearchRequest.QueryExpansionSpec.Condition.AUTO,\n",
    "        ),\n",
    "        spell_correction_spec=discoveryengine.SearchRequest.SpellCorrectionSpec(\n",
    "            mode=discoveryengine.SearchRequest.SpellCorrectionSpec.Mode.AUTO\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    response = client.search(request)\n",
    "    #print(response)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b67904-b47c-487e-b4ec-2c1e72fcdad4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "search_prompt = 'What is the price of Method?'\n",
    "#search_prompt = 'How many Old English items do I have?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ba5c09-c89a-4eb4-a962-0706c875e988",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#search_result = search_sample(PROJECT_ID, LOCATION, 'test-123_1712092317594', search_prompt)\n",
    "search_result = search_sample(PROJECT_ID, LOCATION, 'test-123_1712092317594', search_prompt)\n",
    "\n",
    "print(search_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fb9144-7672-4dbc-8876-9cb37291cb64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(search_result.summary.summary_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44110579-9120-4ec4-96b2-edcf4650ba23",
   "metadata": {},
   "source": [
    "Notice the summary_text section is blank when using structured data. Summary text is only available for unstructured data stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c866297-3f41-409d-ab47-700513c9fb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(search_result.results[0].document.derived_struct_data['snippets'][0]['snippet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e191ad-3432-4210-bf8d-5f70af29f2ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff8d6161-49f9-45b6-9ddb-f517594618e3",
   "metadata": {},
   "source": [
    "In order to provide a summary of the returned results we will pass the output from the query to Gemini to provide more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba25e2f-9c44-4e57-9992-8a516cfe71d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gemini_text(project_id: str, location: str, prompt: str) -> str:\n",
    "    # Initialize Vertex AI\n",
    "    vertexai.init(project=project_id, location=location)\n",
    "    # Load the model\n",
    "    #multimodal_model = GenerativeModel(\"gemini-pro\")\n",
    "    multimodal_model = GenerativeModel(\"gemini-1.5-pro-preview-0409\")\n",
    "    # Query the model\n",
    "    response = multimodal_model.generate_content(\n",
    "        [\n",
    "            #\"what is shown in this image?\",\n",
    "            prompt,\n",
    "        ]\n",
    "    )\n",
    "    #print(response)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bea43ae-7ddf-494b-afa9-203692842ec1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gemini_prompt =  '<CONTEXT> ' + str(search_result) + ' </CONTEXT> ' + search_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef78b97-2874-4ed4-a22d-1ad779642cbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_output = gemini_text(PROJECT_ID, REGION, gemini_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609145e4-507f-45fa-8ff1-9f604516b457",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32866d5b-6c52-4347-aafe-1aea3da2bfbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118d6c01-0ffb-44e7-8c19-1a87bbdb9053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3809bc66-1d82-4306-acb2-ca1d26e0385f",
   "metadata": {},
   "source": [
    "This code will add an unsupporte file type to a data store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c3ff2384-c246-4c1e-8c4a-0fba0964e98d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def text_create_document(project_id, location, datastore_name, document_id, text_content):\n",
    "    # Create a client\n",
    "    client = discoveryengine.DocumentServiceClient()\n",
    "    \n",
    "    # Create the Document object\n",
    "    document = discoveryengine.Document(\n",
    "        content=discoveryengine.Document.Content(\n",
    "            mime_type='text/plain',\n",
    "            raw_bytes=text_content,\n",
    "            uri='gs://rkiles-test/testing/EX11/extension-packs-templates/EX11/MADTREEX11CustOlpnScanHandlerRoute13.vm',\n",
    "        ),\n",
    "        json_data='{\"customer_name\":\"Dollar Tree\", \"customer_code\":\"DTRE\", \"ext_num\":\"EX11\"}'\n",
    "    )\n",
    "\n",
    "    # Initialize request argument(s)\n",
    "    request = discoveryengine.CreateDocumentRequest(\n",
    "        parent=f\"projects/{project_id}/locations/{location}/collections/default_collection/dataStores/{datastore_name}/branches/0\",\n",
    "        document=document,\n",
    "        document_id=document_id,\n",
    "    )\n",
    "\n",
    "    # Make the request\n",
    "    response = client.create_document(request=request)\n",
    "\n",
    "    # Handle the response\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "55cb0da5-2efa-443f-9bb9-e3b9cdfc2596",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_string = 'This is some sample text'\n",
    "byte_string = bytes(text_string, 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6a31df-8492-40b6-abce-ac5f6cf35109",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3bbb3d80-bf89-4d2f-a7f5-82455deb7385",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"projects/246771786686/locations/global/collections/default_collection/dataStores/manh-test/branches/0/documents/document_id-1234\"\n",
      "id: \"document_id-1234\"\n",
      "schema_id: \"default_schema\"\n",
      "json_data: \"{\\\"ext_num\\\":\\\"EX11\\\",\\\"customer_code\\\":\\\"DTRE\\\",\\\"customer_name\\\":\\\"Dollar Tree\\\"}\"\n",
      "parent_document_id: \"document_id-1234\"\n",
      "content {\n",
      "  mime_type: \"text/plain\"\n",
      "  uri: \"gs://rkiles-test/testing/EX11/extension-packs-templates/EX11/MADTREEX11CustOlpnScanHandlerRoute13.vm\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_create_document(PROJECT_ID, LOCATION, 'manh-test', 'document_id-1234', byte_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd93435-584d-471d-bfcf-9e3cbd7f53c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_json = json.loads(qa_response)\n",
    "\n",
    "recordnum = 0\n",
    "\n",
    "for brand in qa_json['products']:\n",
    "    sample_create_document(PROJECT_ID, LOCATION, DSNAME, 'record'+str(recordnum), brand)\n",
    "    recordnum = recordnum + 1\n",
    "    #print(brand)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m113"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
